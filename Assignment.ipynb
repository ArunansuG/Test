{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Dear Candidate,\n",
    "\n",
    "As part of the recuritment process, you're required to complete the assignment detailed below and upload it as detailed in the email.\n",
    "\n",
    "<!-- The assignment tests your knowlege of python programming and machine learning skills. The test is designed to be completed within -- days -- -->\n",
    "\n",
    "Kindly submit your orignal work. \n",
    "\n",
    "Thank you and Good luck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Overview\n",
    "\n",
    "### Problem Statment\n",
    "\n",
    "The goal of this assignment is to train a trading model which tries to predict the stock market direction in the next 5 mins based on the historical data. \n",
    "\n",
    "### Your task\n",
    "At a high level, you've three tasks.\n",
    "\n",
    "<b>Part I - Prepare Data</b> : This section involves reading the data files, modifying the data and preparing 4-5 indicators which will be given as an input to our model. The 4 indicators(RSI, ADX, VOI, OIR) are detailed below. You're required to program these 4 indicators to feed into the model. \n",
    "\n",
    "*Bonus* - You may add any other indicator/feature which you feel could help in increasing the accuracy of the model. \n",
    "\n",
    "<b>Part II - EDA and model training</b> : In this section, you would be required to design a Logistic Regression model. The model is detailed in the section below. You're requried to implement the same model and train it for relevant number of epochs.  \n",
    "\n",
    "*Bonus* - Once you've the suggested model available, you can chose to modify it (in a separate section below) and experiment to see how the changes affect the accuracy of the model.\n",
    "\n",
    "<b>Part III - Model Evaluation </b> : In this section, you would be running your model on your test data to evaluate bias/variance tradeoff\n",
    "\n",
    "### Data\n",
    "Along with this notebook, we've provided you the dataset in the zip file ---name here ---\n",
    "The data is organized by each day, and has order book(refer resources) data for 1s time interval. The various columns are:\n",
    "\n",
    "date: date and time in YYYY-MM-DD hh:mm:ss format\n",
    "\n",
    "Order Book Data: \n",
    "\n",
    "a0: Best ASK price (i.e. the lowest posted price at which someone is willing to sell an asset)\n",
    "\n",
    "b0: Best BID price (i.e. the highest posted price at which someone is willing to buy an asset)\n",
    "\n",
    "az0: Best ASK size (i.e. the number of lots being offered for selling at the lowest ask price)\n",
    "\n",
    "bz0: Best BID size (i.e. the number of lots that people are trying to buy at the bid price)\n",
    "\n",
    " \n",
    "\n",
    "Features:\n",
    "\n",
    "atv: feature representing one fraction of trading volume ( in number of lots )\n",
    "\n",
    "btv: feature representing another fraction of trading volume ( in number of lots )\n",
    "\n",
    "(atv + btv =  total number of trades in the day so far)\n",
    "\n",
    " \n",
    "\n",
    "tbq: sum of all the BID ( buy ) sizes in the market  \n",
    "\n",
    "tsq: sum of all the ASK ( sell ) sizes in the market  \n",
    "\n",
    " \n",
    "\n",
    "All the above variables are for a derivative instrument 2.\n",
    "\n",
    "### Resources\n",
    "1. [Order Book](https://www.investopedia.com/terms/o/order-book.asp)\n",
    "2. [Technical Indicators](https://www.investopedia.com/terms/i/indicator.asp) \n",
    "3. [RSI](https://www.investopedia.com/terms/r/rsi.asp) , [ADX](https://www.investopedia.com/articles/trading/07/adx-trend-indicator.asp), [Calculating ADX](https://traderhq.com/average-directional-index-indicator-guide/)\n",
    "\n",
    "3. Volume Order Imbalance and Order Imabalnce Ratio - refer to Page 5 and 17 of the document [at](http://eprints.maths.ox.ac.uk/1895/1/Darryl%20Shen%20%28for%20archive%29.pdf)\n",
    "4. [Tensorflow](https://www.tensorflow.org/)\n",
    "5. [LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part I Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The first part is designed to test your knowledge of data analysis, and the ability to program in an efficient and logical way. \n",
    "\n",
    "In this section, you'll be implementing two technical indicators(ADX, RSI) and two order book featrues(VOI, OIR) and finally rearranging the data in a format which could be used for training an ML model\n",
    "\n",
    "The class ProcessData is provided which is initialized with daily data from the csv files.\n",
    "\n",
    "<b>Input to the class</b> - 1 day order book data. Shape (22141,8)\n",
    "\n",
    "<b>Expected output</b> - Input features(X) and ouput(Y) which can be fed into a trainable model. This is detailed further in the section. \n",
    "\n",
    "**X**: Shape (Number of points in a day, look_back period, number of technical indicators)<br>\n",
    "Eg. If there are 200 points which are identified for training in a day, with a look back period of 5mins(300 seconds) and 4 features. Then the ouput(X) from createDataset will have a shape of (200, 300, 4)\n",
    "\n",
    "**Y**: Shape(Number of points). This will hold the predications (buy/sell/hold) based on the direction in which \n",
    "        the market will move in the next 5 mins. Use an appropriate threshold to split the data into buy,sell and hold ( e.g.. if the market moves more than 0.1% => Buy, less than -0.1% => Sell, otherwise Hold )\n",
    "        \n",
    "Your task is to implement the following methods:\n",
    "\n",
    "1. computeOHLC - For technical analysis, you're required to conver the order book data to an OHCL format. \n",
    "2. addRSIColumn - This method will compute the RSI for the data(self.data) and assign it in column (self.data[col_name])\n",
    "3. addADXColumn - This method will compute the ADX for the data(self.data) and assign it in column (self.data[col_name]) \n",
    "4. addVOIColumn - This method will compute the VOI for the data(self.data) and assign it in column (self.data[col_name])\n",
    "5. addOIRColumn - This method will compute the OIR for the data(self.data) and assign it in column (self.data[col_name])\n",
    "6. createDataset - Finally, you're required to convert the data into a numpy array which can be utilized for training. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('chained_assignment',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ProcessData:\n",
    "    \"\"\"\n",
    "    Documentation:\n",
    "    Class to processes raw data \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, data, \n",
    "                 path='../dataset', window=1,\n",
    "                 debug=False, convert_to_log=True, local_data=None):\n",
    "        self.debug = debug\n",
    "        self.data = data\n",
    "        if(convert_to_log):\n",
    "            self.convert_to_log_returns()\n",
    "            \n",
    "    def convert_to_log_returns(self):\n",
    "        df = self.data\n",
    "        df['aR0'] = np.log(df['a0']) - np.log(df['a0'].shift(1))\n",
    "        df['bR0'] = np.log(df['b0']) - np.log(df['b0'].shift(1))\n",
    "        df['aR0_cm'] = np.log(df['a0_cm']) - np.log(df['a0_cm'].shift(1))\n",
    "        df['bR0_cm'] = np.log(df['b0_cm']) - np.log(df['b0_cm'].shift(1))\n",
    "        if(0):#False ==self.debug):\n",
    "            df.drop(['a0_cm','b0_cm'], inplace=True, axis=1)\n",
    "    \n",
    "    def computeOHLC(self, interval='1T',column='b0'):\n",
    "        \"\"\"\n",
    "        This method is expected to take a price series as an input, and resample the series to produce OHLC data,\n",
    "        based on the input interval\n",
    "        Input:\n",
    "        interval- time in seconds at which rate the data needs to be resampled\n",
    "        column - name of the column which contains the time series\n",
    "        \n",
    "        Output:\n",
    "        self.dataD is set which should have 4 columns(Open, High, Low, Close) and self.data.shape[0]/interval number\n",
    "        of rows. Such features are required for technical indicators. \n",
    "        \"\"\"\n",
    "        \n",
    "        ### Start your code here ###\n",
    "\n",
    "        ### End your code here ###\n",
    "        \n",
    "    \n",
    "    def addRSIColumn(self,col_name='RSI', period=14, \n",
    "                    base='Close'):\n",
    "        \"\"\"\n",
    "        Add RSI Column\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        layer_name: string\n",
    "            Name of the layer\n",
    "        period: int, default 14\n",
    "            The RSI PERIOD\n",
    "        base: strig from  ['Open','Close','Low','High'], default 'Close'\n",
    "            Base price \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.computeOHLC()\n",
    "        RSI = None\n",
    "        ### Start your code here ###\n",
    "\n",
    "        ### End your code here ###        \n",
    "        self.data[col_name] = RSI\n",
    "        \n",
    "    def addADXColumn(self, col_name = 'ADX', period =14,\n",
    "                           Multiplier = 3):\n",
    "        \"\"\"\n",
    "        Add ADX indicator\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        layer_name: string\n",
    "            Name of the layer\n",
    "        period: int, default 14\n",
    "            The ADX number of periods\n",
    "        Multiplier: int\n",
    "            The ATR multiplier\n",
    "        \"\"\"\n",
    "        self.computeOHLC()\n",
    "        ADX = None\n",
    "        ### Start your code here ###\n",
    "\n",
    "        ### End your code here ###        \n",
    "        self.data[col_name] = ADX\n",
    "        \n",
    "    def addVOIColumn(self, col_name = 'VOI',\n",
    "                    Va='az0', Ra='aR0', Vb='bz0', Rb='bR0'):\n",
    "        if(self.debug):\n",
    "            print(\"Adding VOI Layer\")\n",
    "        \"\"\"\n",
    "        Add Volume Imbalance Column\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        layer_name: string\n",
    "            Name of the layer\n",
    "        Va: string\n",
    "            Ask volume column\n",
    "        Pa: string\n",
    "            Ask price column\n",
    "        Vb: string\n",
    "            Bid volume column\n",
    "        Pb: string\n",
    "            Bid price column\n",
    "        \"\"\"\n",
    "        VOI = None\n",
    "        ### Start your code here ###\n",
    "\n",
    "        ### End your code here ###        \n",
    "        self.data[col_name] = VOI\n",
    "        \n",
    "        \n",
    "    def addOIRColumn(self, col_name = 'OIR',\n",
    "                    Va='az0', Vb='bz0'):\n",
    "        if(self.debug):\n",
    "            print(\"Adding OIR Layer\")\n",
    "        \"\"\"\n",
    "        Add Volume Imbalance Layer\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        layer_name: string\n",
    "            Name of the layer\n",
    "        Va: string\n",
    "            Ask volume column\n",
    "        Vb: string\n",
    "            Bid volume column\n",
    "        \"\"\"\n",
    "        OIR = None\n",
    "        ### Start your code here ###\n",
    "\n",
    "        ### End your code here ###        \n",
    "        self.data[col_name] = OIR\n",
    "    \n",
    "    def createDataset(self,X_cols,lag,freq=100):\n",
    "        '''\n",
    "        \n",
    "        Input features(X) and ouput(Y) which can be fed into a trainable model. This is detailed further in the section. \n",
    "        \n",
    "        X : Shape (Number of points in a day, look_back period, number of technical indicators)<br>\n",
    "        Eg. If there are 200 points which are identified for training in a day, with a look back period of 5mins(300s) and 4 features. Then the ouput,X from createDataset will have a shape of (200, 300, 4)\n",
    "        \n",
    "        Y: Shape(Number of points). This will hold the predications (buy/sell/hold) based on the direction in which \n",
    "        the market has moved in the next 5 mins. Use an appropriate threshold to split the data.\n",
    "        '''\n",
    "        X = np.empty((0,lag,len(X_cols)))\n",
    "        Y = np.empty((0))\n",
    "        ### Start your code here ###\n",
    "        \n",
    "        ### End your code here ###\n",
    "        \n",
    "        assert X.shape[0] == Y.shape[0]\n",
    "        return X , Y\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "days = [20170403,  20170405, 20170406, 20170407,#]#,#20170410,\n",
    "        20170413,20170417,\n",
    "        20170418,20170419,20170420,20170421]#,20170406]\n",
    "training=1\n",
    "days += [20170424,  20170425, 20170426, 20170427,#]#,#20170410,\n",
    "        20170428,20170502,\n",
    "        20170503,20170504,20170505,20170508]#,20170406]\n",
    "\n",
    "days += [20170509,  20170510, 20170511, 20170512,#]#,#20170410,\n",
    "        20170515,20170517,\n",
    "        20170518,20170519,20170522,20170523]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Run the below cell after implementing the required methods in the class above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = {}\n",
    "Y = {}\n",
    "for day in days:\n",
    "    print(day)\n",
    "    data = pd.read_csv('./assignment_data/test_'+str(day)+'.csv',\n",
    "                       index_col='date')\n",
    "    \n",
    "    sData = ProcessData(data, debug=False)\n",
    "    sData.data.index = pd.to_datetime(sData.data.index)\n",
    "    sData.addVOIColumn()\n",
    "    sData.addOIRColumn()\n",
    "    sData.addRSIColumn()\n",
    "    sData.addADXColumn()\n",
    "    X[day], Y[day] = sData.createDataset(X_cols = ['VOI','OIR','ADX','RSI'], lag=300)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X[day].shape, Y[day].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part II EDA and Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this part, you are required to visualize the procssed data and test for such properties at stationariy, heteroskedasticity etc which pertain to time series analysis. This perhaps will be the most important criteria in understanding the data set and coming up with useful features for the next phase Also, feel free to design more features to be used for your model below. \n",
    "\n",
    "Here, you may chose to do some cleanup such as, but not limited to, removing outliers, invalid points etc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X[day].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#sData.data[['VOI','OIR','ADX','RSI']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After going back and forth with EDA and feature engineering, you're required to train your model here and evaluate how it performs on the training set. Necessarily adjustments will need to be made to come up with the right parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self,scope=\"irage/base\",seq_length=300,num_features=4):\n",
    "        ### Start your code here ###\n",
    "\n",
    "\n",
    "        ### End your code here ###\n",
    "        #assert(self.loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model0 = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#np.random.randint(4,size=[32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Run model\n",
    "Add code below to train your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_days = days[:-10]\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"==Epoc==\",epoch)\n",
    "    shuffle(train_days)\n",
    "    \n",
    "    for day in train_days:\n",
    "        ### Start your code here ###\n",
    "        pass\n",
    "        ### End your code here ###\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part III Model Evaluation\n",
    "Here, you'll be analysing how the model performs on validation data. \n",
    "\n",
    "Resources:<br>\n",
    "[Model Accuracy](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/05/history_training_dataset.png)<br>\n",
    "[Bias Variance Trade-off](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)\n",
    "\n",
    "Based on the analysis you may have to go back to the model and control for overfitting etc. This will be a continuos process until you've satisfactory results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_days = days[-10:]\n",
    "\n",
    "for day in test_days:\n",
    "    ### Start your code here ###\n",
    "    pass\n",
    "    ### End your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Bonus Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the basic Neural Network model with the fully-connected layers, you may try replicating the model below and evaluate how the performance is afffected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/LSTM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "Model Architecture: Here is a snapshot of the necessary layers(in that order)<br>\n",
    "1. LSTM for one sample. This will take self.feat as the input(eg ?,300,4) and generate an LSTM output which will feed into the next layers\n",
    "2. LSTM for the entire batch. This will take output from first LSTM and generate an output across the entire batch.<br>\n",
    "Hint - The state ouputs will need to be preserved in case you decide to break a days' data into multiple mini-batches.\n",
    "For both the above layers, you may refer to the following tensorflow methods:<br>\n",
    "a. LSTM Cell - https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LayerNormBasicLSTMCell<br>\n",
    "b. RNN - https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\n",
    "\n",
    "3. Full connected layer(s) - Add 1 or more fully connected layer to the output from 2 above. https://www.tensorflow.org/api_docs/python/tf/layers/dense\n",
    "\n",
    "4. Loss function and optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
